[paths]
tagger_model = null
ner_model = null

[nlp]
lang = "tr"
pipeline = ["tok2vec", "tagger", "morphologizer", "lemmatizer", "parser", "ner"]
tokenizer = {"@tokenizers":"spacy.Tokenizer.v1"}

[initialize]
vectors = ${paths.tagger_model}

[components]

[components.tok2vec]
source = ${paths.tagger_model}
component = "tok2vec"


[components.tagger]
source = ${paths.tagger_model}
component = "tagger"

[components.morphologizer]
source = ${paths.tagger_model}
component = "morphologizer"


[components.trainable_lemmatizer]
source = ${paths.tagger_model}
component = "trainable_lemmatizer"
replace_listeners = ["model.tok2vec"]


[components.parser]
source = ${paths.tagger_model}
component = "parser"

[components.ner]
source = ${paths.ner_model}
component = "ner"
replace_listeners = ["model.tok2vec"]

